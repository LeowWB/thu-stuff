{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2041270a-b2b5-462c-99ee-abde6d1e6d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from random import seed, randrange\n",
    "import numpy as np\n",
    "\n",
    "seed(0)\n",
    "newsgroups = fetch_20newsgroups(remove=('headers', 'footers', 'quotes'))\n",
    "\n",
    "D = len(newsgroups.data)\n",
    "K = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69370a26-6fdd-4c09-a54b-369e5c7fdeb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I was wondering if anyone out there could enlighten me on this car I saw\\nthe other day. It was a 2-door sports car, looked to be from the late 60s/\\nearly 70s. It was called a Bricklin. The doors were really small. In addition,\\nthe front bumper was separate from the rest of the body. This is \\nall I know. If anyone can tellme a model name, engine specs, years\\nof production, where this car is made, history, or whatever info you\\nhave on this funky looking car, please e-mail.'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newsgroups.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "44b3cd94-0279-4664-a951-b9d250c3f049",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english', min_df=2, token_pattern=r'[A-Za-z][A-Za-z]+')\n",
    "T = vectorizer.fit_transform(newsgroups.data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb897c14-999c-4167-9a5a-92df41ce3f84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 33815)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a54e1f9e-2062-48d0-b13e-2bedf168f5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topics: 50, vocab size: 33815, docs: 11314\n"
     ]
    }
   ],
   "source": [
    "W = T.shape[1]\n",
    "print(f'topics: {K}, vocab size: {W}, docs: {D}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c465a70-b79c-4d28-bf59-153f773c4d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_names = vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40e53de5-dae4-42d8-961b-851c4a66824d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pi = []\n",
    "for i in range(D):\n",
    "    pi.append(i%K)\n",
    "pi = np.array(pi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9e37c8eb-a829-4f2f-87d5-7f7a5aaa4f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = np.zeros((K, W))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4d5ca487-d883-46eb-aa5b-41f73edf15df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 1, num docs w changed topics 213\n",
      "iter 2, num docs w changed topics 172\n",
      "iter 3, num docs w changed topics 271\n",
      "iter 4, num docs w changed topics 189\n",
      "iter 5, num docs w changed topics 218\n",
      "iter 6, num docs w changed topics 235\n",
      "iter 7, num docs w changed topics 156\n",
      "iter 8, num docs w changed topics 216\n",
      "iter 9, num docs w changed topics 135\n",
      "iter 10, num docs w changed topics 118\n",
      "iter 11, num docs w changed topics 67\n",
      "iter 12, num docs w changed topics 62\n",
      "iter 13, num docs w changed topics 158\n",
      "iter 14, num docs w changed topics 102\n",
      "iter 15, num docs w changed topics 141\n",
      "iter 16, num docs w changed topics 102\n",
      "iter 17, num docs w changed topics 89\n",
      "iter 18, num docs w changed topics 131\n",
      "iter 19, num docs w changed topics 36\n",
      "iter 20, num docs w changed topics 61\n",
      "iter 21, num docs w changed topics 94\n",
      "iter 22, num docs w changed topics 64\n",
      "iter 23, num docs w changed topics 215\n",
      "iter 24, num docs w changed topics 140\n",
      "iter 25, num docs w changed topics 171\n",
      "iter 26, num docs w changed topics 105\n",
      "iter 27, num docs w changed topics 129\n",
      "iter 28, num docs w changed topics 203\n",
      "iter 29, num docs w changed topics 55\n",
      "iter 30, num docs w changed topics 110\n",
      "iter 31, num docs w changed topics 106\n",
      "iter 32, num docs w changed topics 87\n",
      "iter 33, num docs w changed topics 216\n",
      "iter 34, num docs w changed topics 197\n",
      "iter 35, num docs w changed topics 169\n",
      "iter 36, num docs w changed topics 119\n",
      "iter 37, num docs w changed topics 257\n",
      "iter 38, num docs w changed topics 309\n",
      "iter 39, num docs w changed topics 160\n",
      "iter 40, num docs w changed topics 225\n",
      "iter 41, num docs w changed topics 150\n",
      "iter 42, num docs w changed topics 221\n",
      "iter 43, num docs w changed topics 133\n",
      "iter 44, num docs w changed topics 199\n",
      "iter 45, num docs w changed topics 165\n",
      "iter 46, num docs w changed topics 134\n",
      "iter 47, num docs w changed topics 284\n",
      "iter 48, num docs w changed topics 178\n",
      "iter 49, num docs w changed topics 282\n",
      "iter 50, num docs w changed topics 343\n",
      "iter 51, num docs w changed topics 186\n",
      "iter 52, num docs w changed topics 326\n",
      "iter 53, num docs w changed topics 54\n",
      "iter 54, num docs w changed topics 147\n",
      "iter 55, num docs w changed topics 128\n",
      "iter 56, num docs w changed topics 188\n",
      "iter 57, num docs w changed topics 109\n",
      "iter 58, num docs w changed topics 67\n",
      "iter 59, num docs w changed topics 265\n",
      "iter 60, num docs w changed topics 153\n",
      "iter 61, num docs w changed topics 168\n",
      "iter 62, num docs w changed topics 145\n",
      "iter 63, num docs w changed topics 17\n",
      "iter 64, num docs w changed topics 77\n",
      "iter 65, num docs w changed topics 92\n",
      "iter 66, num docs w changed topics 131\n",
      "iter 67, num docs w changed topics 28\n",
      "iter 68, num docs w changed topics 20\n",
      "iter 69, num docs w changed topics 130\n",
      "iter 70, num docs w changed topics 26\n",
      "iter 71, num docs w changed topics 108\n",
      "iter 72, num docs w changed topics 48\n",
      "iter 73, num docs w changed topics 7\n",
      "iter 74, num docs w changed topics 34\n",
      "iter 75, num docs w changed topics 44\n",
      "iter 76, num docs w changed topics 73\n",
      "iter 77, num docs w changed topics 12\n",
      "iter 78, num docs w changed topics 7\n",
      "iter 79, num docs w changed topics 44\n",
      "iter 80, num docs w changed topics 4\n",
      "iter 81, num docs w changed topics 28\n",
      "iter 82, num docs w changed topics 13\n",
      "iter 83, num docs w changed topics 1\n",
      "iter 84, num docs w changed topics 16\n",
      "iter 85, num docs w changed topics 19\n",
      "iter 86, num docs w changed topics 21\n",
      "iter 87, num docs w changed topics 7\n",
      "iter 88, num docs w changed topics 2\n",
      "iter 89, num docs w changed topics 21\n",
      "iter 90, num docs w changed topics 1\n",
      "iter 91, num docs w changed topics 4\n",
      "iter 92, num docs w changed topics 3\n",
      "iter 93, num docs w changed topics 1\n",
      "iter 94, num docs w changed topics 9\n",
      "iter 95, num docs w changed topics 6\n",
      "iter 96, num docs w changed topics 7\n",
      "iter 97, num docs w changed topics 0\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "iter_no = 1\n",
    "current_docset_ind = 0\n",
    "\n",
    "while True:\n",
    "    current_docset_ind = (current_docset_ind + 1) % 10\n",
    "    docset = range(int(current_docset_ind/10*D), int((current_docset_ind+1)/10*D))\n",
    "    for topic in range(K):\n",
    "        total_words_in_topic = W\n",
    "        word_dist_in_topic = np.ones((W))\n",
    "        for doc in docset:\n",
    "            if pi[doc] != topic:\n",
    "                continue\n",
    "            word_dist_in_topic += T[doc]\n",
    "            total_words_in_topic += np.sum(T[doc])\n",
    "        if total_words_in_topic > 0:\n",
    "            word_dist_in_topic /= total_words_in_topic\n",
    "        else:\n",
    "            word_dist_in_topic = np.ones((W)) / W\n",
    "        mu[topic] = word_dist_in_topic\n",
    "\n",
    "    log_mu = np.log(mu, out=np.zeros_like(mu), where=(mu!=0))\n",
    "    old_pi = np.copy(pi)\n",
    "    \n",
    "    for doc in docset:\n",
    "        max_log_prob = -np.inf\n",
    "        max_log_prob_topic = -1\n",
    "        for topic in range(K):\n",
    "            log_probability_of_doc_given_topic = np.dot(log_mu[topic], T[doc])\n",
    "            if log_probability_of_doc_given_topic > max_log_prob:\n",
    "                max_log_prob = log_probability_of_doc_given_topic\n",
    "                max_log_prob_topic = topic\n",
    "        pi[doc] = max_log_prob_topic\n",
    "        \n",
    "    num_docs_changed = np.count_nonzero(pi - old_pi)\n",
    "    print(f'iter {iter_no}, num docs w changed topics {num_docs_changed}')\n",
    "    \n",
    "    if num_docs_changed == 0:\n",
    "        print('done.')\n",
    "        break\n",
    "    \n",
    "    iter_no += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f0da48f-2ec8-4782-8f7f-4caef3e49844",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([13, 13, 13, ..., 36, 36, 13])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b156c710-8b97-4ca3-8601-226abc38321f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1513\n",
      "36\n",
      "18\n",
      "21\n",
      "39\n",
      "20\n",
      "29\n",
      "20\n",
      "30\n",
      "466\n",
      "34\n",
      "30\n",
      "20\n",
      "982\n",
      "1459\n",
      "21\n",
      "82\n",
      "991\n",
      "33\n",
      "964\n",
      "914\n",
      "13\n",
      "38\n",
      "27\n",
      "29\n",
      "30\n",
      "26\n",
      "24\n",
      "28\n",
      "21\n",
      "31\n",
      "26\n",
      "36\n",
      "28\n",
      "40\n",
      "127\n",
      "965\n",
      "124\n",
      "23\n",
      "31\n",
      "906\n",
      "22\n",
      "563\n",
      "25\n",
      "24\n",
      "35\n",
      "290\n",
      "21\n",
      "23\n",
      "16\n"
     ]
    }
   ],
   "source": [
    "for i in range(K):\n",
    "    print(np.count_nonzero(pi==i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fd7fac1-2e48-4a7f-9d53-f735cee551fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic in range(K):\n",
    "    total_words_in_topic = 0\n",
    "    word_dist_in_topic = np.zeros((W))\n",
    "    for doc in range(D):\n",
    "        if pi[doc] != topic:\n",
    "            continue\n",
    "        word_dist_in_topic += T[doc]\n",
    "        total_words_in_topic += np.sum(T[doc])\n",
    "    word_dist_in_topic /= total_words_in_topic\n",
    "    mu[topic] = word_dist_in_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2bb1b069-08f0-41ff-a591-a89a5744abd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic 0: ['time' 'use' 'does' 'god' 'think' 'know' 'people' 'like' 'just' 'don']\n",
      "topic 1: ['server' 'usr' 'mit' 'subject' 'pub' 'attack' 'file' 'use' 'available'\n",
      " 'edu']\n",
      "topic 2: ['chicago' 'leads' 'san' 'york' 'new' 'idle' 'guide' 'borland' 'lost'\n",
      " 'won']\n",
      "topic 3: ['history' 'ra' 'professor' 'church' 'turkish' 'god' 'jesus' 'greek'\n",
      " 'university' 'bible']\n",
      "topic 4: ['eof' 'available' 'oname' 'printf' 'ftp' 'op' 'entry' 'program' 'file'\n",
      " 'output']\n",
      "topic 5: ['space' 'lens' 'library' 'professor' 'armenian' 'st' 'university'\n",
      " 'libxmu' 'xmu' 'lib']\n",
      "topic 6: ['tm' 'di' 'wm' 'ei' 'bxn' 'bhj' 'giz' 'pl' 'max' 'ax']\n",
      "topic 7: ['dr' 'crypto' 'rates' 'recipient' 'conference' 'program' 'university'\n",
      " 'barbara' 'santa' 'kk']\n",
      "topic 8: ['chip' 'law' 'dead' 'police' 'serial' 'bullock' 'number' 'people' 'maria'\n",
      " 'said']\n",
      "topic 9: ['com' 'available' 'dos' 'know' 'does' 'windows' 'edu' 'just' 'like' 'use']\n",
      "topic 10: ['pm' 'committee' 'mail' 'people' 'anonymity' 'anon' 'service' 'posting'\n",
      " 'edu' 'anonymous']\n",
      "topic 11: ['mr' 'mj' 'azerbaijan' 'people' 'period' 'pp' 'ted' 'colorado' 'cs' 'edu']\n",
      "topic 12: ['team' 'vancouver' 'armenians' 'san' 'dr' 'calgary' 'vs' 'pt' 'la' 'pts']\n",
      "topic 13: ['jesus' 'use' 'does' 'time' 'think' 'don' 'just' 'like' 'know' 'people']\n",
      "topic 14: ['time' 'does' 'new' 'edu' 'just' 'know' 'don' 'file' 'like' 'use']\n",
      "topic 15: ['bhj' 'ey' 'giz' 'tm' 'file' 'pl' 'output' 'ei' 'max' 'ax']\n",
      "topic 16: ['source' 'files' 'judas' 'data' 'entries' 'program' 'edu' 'use' 'entry'\n",
      " 'image']\n",
      "topic 17: ['good' 'time' 'use' 'does' 'think' 'know' 'people' 'like' 'don' 'just']\n",
      "topic 18: ['des' 'mail' 'pem' 'com' 'use' 'pgp' 'public' 'rsa' 'key' 'ripem']\n",
      "topic 19: ['time' 'does' 'good' 'use' 'think' 'know' 'just' 'like' 'don' 'people']\n",
      "topic 20: ['does' 'time' 'stephanopoulos' 'think' 'people' 'like' 'mr' 'just' 'know'\n",
      " 'don']\n",
      "topic 21: ['toolkit' 'type' 'aircraft' 'ground' 'test' 'warning' 'lost' 'won'\n",
      " 'april' 'water']\n",
      "topic 22: ['gm' 'ei' 'com' 'pl' 'server' 'available' 'xfree' 'edu' 'max' 'ax']\n",
      "topic 23: ['went' 'sumgait' 'didn' 'don' 'saw' 'said' 'armenians' 'armenian'\n",
      " 'people' 'know']\n",
      "topic 24: ['abs' 'fluids' 'brake' 'oil' 'dot' 'cal' 'flames' 'car' 'kings' 'jews']\n",
      "topic 25: ['yx' 'mc' 'lk' 'gc' 'ck' 'qs' 'hz' 'sc' 'scx' 'cx']\n",
      "topic 26: ['screen' 'promo' 'center' 'dg' 'military' 'ssf' 'yes' 'tax' 'sleeve'\n",
      " 'picture']\n",
      "topic 27: ['ottomans' 'sharks' 'ottoman' 'games' 'history' 'professor' 'jewish'\n",
      " 'university' 'season' 'jews']\n",
      "topic 28: ['cs' 'programmer' 'people' 'program' 'azerbaijan' 'armenian' 'comp' 'com'\n",
      " 'os' 'edu']\n",
      "topic 29: ['data' 'single' 'drives' 'st' 'dept' 'jumper' 'slave' 'master' 'water'\n",
      " 'drive']\n",
      "topic 30: ['secret' 'time' 'new' 'di' 'south' 'war' 'space' 'dod' 'max' 'ax']\n",
      "topic 31: ['turkish' 'magi' 'bxn' 'tm' 'com' 'wm' 'edu' 'pl' 'max' 'ax']\n",
      "topic 32: ['good' 'internet' 'eff' 'pub' 'si' 'cs' 'privacy' 'bh' 'mov' 'db']\n",
      "topic 33: ['shall' 'license' 'going' 'military' 'weapon' 'firearm' 'section'\n",
      " 'president' 'stephanopoulos' 'mr']\n",
      "topic 34: ['type' 'xt' 'value' 'set' 'window' 'resource' 'visual' 'application'\n",
      " 'dos' 'widget']\n",
      "topic 35: ['games' 'nhl' 'season' 'launch' 'league' 'edu' 'new' 'year' 'team'\n",
      " 'hockey']\n",
      "topic 36: ['good' 'does' 'think' 'time' 'know' 'god' 'don' 'just' 'like' 'people']\n",
      "topic 37: ['didn' 'edu' 'know' 'gif' 'don' 'said' 'image' 'file' 'people' 'jpeg']\n",
      "topic 38: ['vs' 'war' 'jewish' 'pope' 'did' 'book' 'nazis' 'turkey' 'jews' 'turkish']\n",
      "topic 39: ['don' 'rules' 'use' 'program' 'think' 'president' 'entries' 'entry' 'ms'\n",
      " 'myers']\n",
      "topic 40: ['use' 'time' 'max' 'think' 'know' 'don' 'people' 'just' 'like' 'ax']\n",
      "topic 41: ['mw' 'chz' 'pl' 'lk' 'ck' 'qs' 'cx' 'hz' 'uw' 'ww']\n",
      "topic 42: ['does' 'say' 'good' 'time' 'think' 'know' 'like' 'just' 'don' 'people']\n",
      "topic 43: ['ye' 'john' 'bible' 'players' 'libx' 'jesus' 'gm' 'lib' 'god' 'ra']\n",
      "topic 44: ['ey' 'giz' 'ei' 'pl' 'ql' 'di' 'tm' 'um' 'max' 'ax']\n",
      "topic 45: ['people' 'technology' 'ei' 'new' 'encryption' 'pl' 'edu' 'com' 'max' 'ax']\n",
      "topic 46: ['know' 'time' 'god' 've' 'work' 'like' 'don' 'think' 'just' 'people']\n",
      "topic 47: ['bm' 'bos' 'tb' 'win' 'phi' 'har' 'sj' 'henrik' 'gm' 'flyers']\n",
      "topic 48: ['oj' 'ah' 'rk' 'bh' 'bhj' 'key' 'mk' 'di' 'max' 'ax']\n",
      "topic 49: ['card' 'feature' 'controller' 'st' 'rom' 'drive' 'bios' 'hard' 'drives'\n",
      " 'disk']\n"
     ]
    }
   ],
   "source": [
    "for topic in range(K):\n",
    "    top_ten_indices = sorted(range(W), key=lambda w: mu[topic][w])[-10:]\n",
    "    top_ten_for_this_topic = word_names[top_ten_indices]\n",
    "    print(f'topic {topic}: {top_ten_for_this_topic}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
